"""
é…ç½®æ–‡ä»¶
"""
import os
from pathlib import Path
from dotenv import load_dotenv
from dataclasses import dataclass
from typing import Optional, List, Dict

# é¡¹ç›®æ ¹ç›®å½•
BASE_DIR = Path(__file__).resolve().parent

# å°è¯•å¤šä¸ªä½ç½®åŠ è½½ .env æ–‡ä»¶
def load_environment():
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    env_paths = [
        BASE_DIR / '.env',           # å½“å‰ç›®å½•
        BASE_DIR.parent / '.env',    # ä¸Šçº§ç›®å½•  
        BASE_DIR / 'example.env',    # ç¤ºä¾‹æ–‡ä»¶
        BASE_DIR.parent / 'example.env'
    ]
    
    for env_path in env_paths:
        if env_path.exists():
            load_dotenv(env_path)
            print(f"åŠ è½½é…ç½®æ–‡ä»¶: {env_path.name}")
            return True
    
    print("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    return False

# åŠ è½½ç¯å¢ƒå˜é‡
load_environment()

class Config:
    """é…ç½®ç±»"""
    
    # GitHubé…ç½®
    GITHUB_TOKEN = os.getenv('GITHUB_ACCESS_TOKEN', '')

    # ä»“åº“é…ç½®
    REPO_OWNER = os.getenv('REPO_OWNER', '')
    REPO_NAME = os.getenv('REPO_NAME', '')
    
    # OpenAIé…ç½®
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
    OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-3.5-turbo')
    
    # Ollamaé…ç½®
    OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
    
    # æ¨¡å‹é…ç½®
    FAST_MODEL = os.getenv('FAST_MODEL', 'qwen2.5-coder:7b')  # å¿«é€Ÿå“åº”
    QUALITY_MODEL = os.getenv('QUALITY_MODEL', 'qwen2.5-coder:32b')  # é«˜è´¨é‡
    
    # ä¼ä¸šå¾®ä¿¡é…ç½®
    WECHAT_WEBHOOK_URL = os.getenv('WECHAT_WEBHOOK_URL', '')
    
    # ç›‘æ§é…ç½®
    MONITOR_INTERVAL = int(os.getenv('MONITOR_INTERVAL', '300'))  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    BATCH_PROCESS_TIME = os.getenv('BATCH_PROCESS_TIME', '02:00')  # å¤œé—´æ‰¹å¤„ç†æ—¶é—´
    
    # APIé…ç½®
    API_TIMEOUT = int(os.getenv('API_TIMEOUT', '30'))
    API_RETRY_COUNT = int(os.getenv('API_RETRY_COUNT', '3'))
    
    @classmethod
    def validate(cls):
        """éªŒè¯å¿…éœ€çš„é…ç½®"""
        errors = []
        
        if not cls.GITHUB_TOKEN:
            errors.append("ç¼ºå°‘ GITHUB_ACCESS_TOKEN")
        elif len(cls.GITHUB_TOKEN) < 20:
            errors.append("GITHUB_ACCESS_TOKEN æ ¼å¼ä¸æ­£ç¡®")
            
        if not cls.REPO_OWNER:
            errors.append("ç¼ºå°‘ REPO_OWNER")
            
        if not cls.REPO_NAME:
            errors.append("ç¼ºå°‘ REPO_NAME")
        
        return errors
    
    @classmethod
    def get_masked_token(cls, token):
        """è·å–è„±æ•çš„tokenï¼ˆç”¨äºæ—¥å¿—ï¼‰"""
        if not token:
            return "æœªé…ç½®"
        if len(token) < 8:
            return "***"
        return f"{token[:4]}...{token[-4:]}"
    
    @classmethod
    def print_config(cls):
        """æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆè„±æ•ï¼‰"""
        print("\nğŸ“‹ å½“å‰é…ç½®:")
        print(f"   GitHub Token: {cls.get_masked_token(cls.GITHUB_TOKEN)}")
        print(f"   ä»“åº“: {cls.REPO_OWNER}/{cls.REPO_NAME}")
        print(f"   OpenAI Key: {cls.get_masked_token(cls.OPENAI_API_KEY)}")
        print(f"   Ollama URL: {cls.OLLAMA_BASE_URL}")
        
        # éªŒè¯é…ç½®
        errors = cls.validate()
        if errors:
            print("\nâš ï¸  é…ç½®é—®é¢˜:")
            for error in errors:
                print(f"   {error}")
        else:
            print("âœ… é…ç½®éªŒè¯é€šè¿‡")

def check_config():
    """æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®"""
    return len(Config.validate()) == 0
    