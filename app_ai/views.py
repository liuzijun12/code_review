from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods, require_GET, require_POST
from django.utils import timezone
import json
from .git_client import GitHubWebhookClient, GitHubDataClient
from .schemas import is_valid_async_data_type, ASYNC_DATA_TYPES, success_response, error_response
from .tasks.async_get import fetch_github_data_async
from .tasks.async_push import start_push_task
from celery.result import AsyncResult
import logging

logger = logging.getLogger(__name__)


# ==================== Webhookå¤„ç† ====================

@csrf_exempt
@require_http_methods(["POST"])
def git_webhook(request):
    """GitHub webhookå¤„ç†å™¨ - å¼‚æ­¥ç‰ˆæœ¬"""
    # import pdb
    # pdb.set_trace()
    try:
        import json
        body = request.body.decode('utf-8')
        payload_data = json.loads(body)
        
        # æå–ä»“åº“ä¿¡æ¯
        repo_info = payload_data.get('repository', {})
        repo_name = repo_info.get('name')
        repo_owner = repo_info.get('owner', {}).get('login')
        
    except (json.JSONDecodeError, AttributeError):
        repo_name = None
        repo_owner = None
    
    github_client = GitHubWebhookClient()
    is_valid, error_response_data, payload = github_client.validate_webhook_request(request, repo_owner, repo_name)
    
    if not is_valid:
        return error_response_data

    b = request.META
    event_type = request.META.get('HTTP_X_GITHUB_EVENT', '')
    logger.info(f"å¤„ç†webhookäº‹ä»¶: {event_type}")
    
    # å¤„ç†pushäº‹ä»¶ï¼Œè‡ªåŠ¨è§¦å‘å¼‚æ­¥æ•°æ®è·å–å’Œåˆ†æ
    if event_type == 'push':
        try:
            # ä½¿ç”¨å°è£…çš„æ–¹æ³•ä» payload ä¸­è·å–æœ€æ–°æäº¤çš„ SHA
            latest_sha, sha_source = github_client.extract_latest_commit_sha(payload)
            
            if not latest_sha:
                logger.error("æ— æ³•ä» payload ä¸­è·å–æœ€æ–°æäº¤ SHA")
                return JsonResponse(error_response('æ— æ³•è·å–æœ€æ–°æäº¤ SHA', 400), status=400)
            
            # éªŒè¯ SHA æ ¼å¼
            if not github_client.validate_commit_sha(latest_sha):
                logger.error(f"æå–çš„ SHA æ ¼å¼æ— æ•ˆ: {latest_sha}")
                return JsonResponse(error_response(f'æå–çš„ SHA æ ¼å¼æ— æ•ˆ: {latest_sha}', 400), status=400)
            
            # å¯åŠ¨å¼‚æ­¥GitHubæ•°æ®è·å–ä»»åŠ¡ - åªå¤„ç†å•ä¸ªæäº¤
            task = fetch_github_data_async.delay(
                data_type='commit_details',
                repo_owner=repo_owner,
                repo_name=repo_name,
                sha=latest_sha,
                include_diff=True
            )
            
            logger.info(f"ğŸš€ Webhookè§¦å‘å¼‚æ­¥ä»»åŠ¡: {task.id}, å¤„ç†æäº¤: {latest_sha[:8]} (æ¥æº: {sha_source})")
            
            return JsonResponse(success_response({
                'event_type': event_type,
                'message': f'Pushäº‹ä»¶å¤„ç†æˆåŠŸï¼Œå·²å¯åŠ¨å•ä¸ªæäº¤çš„å¼‚æ­¥æ•°æ®è·å–å’ŒAIåˆ†æ',
                'async_task_id': task.id,
                'commit_sha': latest_sha,
                'commit_short_sha': latest_sha[:8],
                'sha_source': sha_source,
                'repository': payload.get('repository', {}).get('full_name', 'unknown'),
                'branch': payload.get('ref', 'refs/heads/main').replace('refs/heads/', ''),
                'total_commits_in_push': len(payload.get('commits', [])),
                'check_url': f'/ai/task-status/{task.id}/'
            }))
            
        except Exception as e:
            logger.error(f"Webhookå¼‚æ­¥ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")
            return JsonResponse(error_response(f'å¼‚æ­¥ä»»åŠ¡å¯åŠ¨å¤±è´¥: {str(e)}', 500), status=500)
    
    elif event_type == 'ping':
        return JsonResponse(success_response({
            'event_type': event_type,
            'message': 'Webhook pingäº‹ä»¶å¤„ç†æˆåŠŸ',
            'repository': payload.get('repository', {}).get('full_name', 'unknown')
        }))
    
    else:
        logger.info(f"å¿½ç•¥äº‹ä»¶ç±»å‹: {event_type}")
        return JsonResponse(success_response({
            'event_type': event_type,
            'message': f'äº‹ä»¶ç±»å‹ {event_type} å·²å¿½ç•¥'
        }))


# ==================== åŒæ­¥æ•°æ®æ¥å£ ====================

@require_GET
def get_github_data(request):
    """åŒæ­¥è·å–GitHubæ•°æ®æ¥å£"""
    data_type = request.GET.get('type', '').strip()
    if not data_type:
        return JsonResponse(error_response("Missing required parameter: type", 400), status=400)
    
    if not is_valid_async_data_type(data_type):
        return JsonResponse(error_response(
            f'Invalid data type. Must be one of: {", ".join(ASYNC_DATA_TYPES)}', 400
        ), status=400)
    
    # è·å–ä»“åº“ä¿¡æ¯
    repo_owner = request.GET.get('repo_owner', '').strip()
    repo_name = request.GET.get('repo_name', '').strip()
    
    # ç®€åŒ–å‚æ•°å¤„ç†ï¼Œåªè·å–åŸºæœ¬å‚æ•°
    params = {
        'branch': request.GET.get('branch', 'main'),
        'limit': int(request.GET.get('limit', 10)),
        'sha': request.GET.get('sha', ''),
        'include_diff': request.GET.get('include_diff', 'true').lower() == 'true'
    }
    
    # ä½¿ç”¨ä»“åº“ä¿¡æ¯åˆ›å»ºå®¢æˆ·ç«¯
    data_client = GitHubDataClient(repo_owner=repo_owner, repo_name=repo_name)
    result = data_client.get_data(data_type, **params)
    
    if result.get('status') == 'error':
        return JsonResponse(error_response(
            result.get('error', 'Unknown error'), 500
        ), status=500)
    
    # è‡ªåŠ¨ä¿å­˜åˆ°æ•°æ®åº“
    _save_data_to_database(data_type, result, data_client)
    
    return JsonResponse(success_response(result))


def _save_data_to_database(result, data_type, data_client):
    """ç»Ÿä¸€çš„æ•°æ®åº“ä¿å­˜é€»è¾‘"""
    if data_type == 'commit_details' and result.get('status') == 'success':
        _save_single_commit(result)
    elif data_type == 'recent_commits' and result.get('status') == 'success':
        _save_recent_commits_batch(result, data_client)


def _save_single_commit(result):
    """ä¿å­˜å•ä¸ªæäº¤åˆ°æ•°æ®åº“"""
    try:
        if 'commit_detail' in result and 'commit' in result['commit_detail']:
            commit_detail = result['commit_detail']['commit']
            github_data = {
                'sha': commit_detail['sha'],
                'commit': {
                    'author': {
                        'name': commit_detail['author']['name'],
                        'email': commit_detail['author']['email'],
                        'date': commit_detail['timestamp']['authored_date']
                    },
                    'message': commit_detail['message']
                },
                'author': {
                    'login': commit_detail['author']['username'],
                    'avatar_url': commit_detail['author'].get('avatar_url')
                },
                'html_url': commit_detail['urls']['html_url'],
                'url': commit_detail['urls']['api_url'],
                'stats': commit_detail.get('stats', {}),
                'files': commit_detail.get('files', []),
                'parents': commit_detail.get('parents', [])
            }
            
            # æ•°æ®åº“ä¿å­˜åŠŸèƒ½å·²ç§»é™¤
            result['database_save'] = {
                'success': True,
                'message': 'æ•°æ®åº“ä¿å­˜åŠŸèƒ½å·²ç¦ç”¨',
                'commit_saved': None
            }
            
    except Exception as e:
        result['database_save'] = {
            'success': False,
            'message': f'æ•°æ®åº“ä¿å­˜å¤±è´¥: {str(e)}',
            'commit_saved': None
        }


# _save_recent_commits_batch å‡½æ•°å·²åˆ é™¤ï¼Œç°åœ¨åªæ”¯æŒå•ä¸ªæäº¤å¤„ç†
        
# ==================== å¼‚æ­¥æ¥å£ ====================

@require_POST
@csrf_exempt
def get_github_data_async(request):
    """å¼‚æ­¥è·å–GitHubæ•°æ®æ¥å£"""
    try:
        try:
            data = json.loads(request.body)
        except json.JSONDecodeError:
            return JsonResponse(error_response(
                'body', 'Invalid JSON format'
            ), status=400)
        
        data_type = data.get('type', '').strip()
        if not data_type:
            return JsonResponse(error_response("Missing required parameter: " + 'type'), status=400)
        
        if not is_valid_async_data_type(data_type):
            return JsonResponse(error_response(
                f'Invalid data type. Must be one of: {", ".join(ASYNC_DATA_TYPES)}', 400
            ), status=400)
        
        # è·å–ä»“åº“ä¿¡æ¯
        repo_owner = data.get('repo_owner', '').strip()
        repo_name = data.get('repo_name', '').strip()
        params = data.get('params', {})
        
        task = fetch_github_data_async.delay(
            data_type, 
            repo_owner=repo_owner, 
            repo_name=repo_name, 
            **params
        )
        
        logger.info(f"å¯åŠ¨å¼‚æ­¥GitHubæ•°æ®è·å–ä»»åŠ¡: {task.id}, ç±»å‹: {data_type}")
        
        return JsonResponse(success_response({
            'task_id': task.id,
            'status': 'pending',
            'message': f'å¼‚æ­¥ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨è·å– {data_type} æ•°æ®',
            'data_type': data_type,
            'params': params,
            'check_url': f'/ai/task-status/{task.id}/'
        }))
        
    except Exception as e:
        return JsonResponse(error_response(str(e)), status=500)


@require_GET
def get_task_status(request, task_id):
    """è·å–å¼‚æ­¥ä»»åŠ¡çŠ¶æ€"""
    try:
        task_result = AsyncResult(task_id)
        
        if task_result.state == 'PENDING':
            response = {
                'task_id': task_id,
                'status': 'pending',
                'message': 'ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­...',
                'progress': None
            }
        elif task_result.state == 'SUCCESS':
            response = {
                'task_id': task_id,
                'status': 'completed',
                'message': 'ä»»åŠ¡æ‰§è¡Œå®Œæˆ',
                'result': task_result.result
            }
        elif task_result.state == 'FAILURE':
            response = {
                'task_id': task_id,
                'status': 'failed',
                'message': 'ä»»åŠ¡æ‰§è¡Œå¤±è´¥',
                'error': str(task_result.info)
            }
        else:
            response = {
                'task_id': task_id,
                'status': task_result.state.lower(),
                'message': f'ä»»åŠ¡çŠ¶æ€: {task_result.state}',
                'info': str(task_result.info) if task_result.info else None
            }
        
        return JsonResponse(success_response(response))
        
    except Exception as e:
        return JsonResponse(error_response(str(e)), status=500)


@require_GET
def get_recent_commits_async_start(request):
    """å¿«é€Ÿå¯åŠ¨å¼‚æ­¥è·å–æœ€è¿‘æäº¤çš„ä»»åŠ¡ (å·²åºŸå¼ƒ)"""
    return JsonResponse(error_response(
        'This API is deprecated. Only single commit processing is supported via webhook events.', 
        400
    ), status=400)


@require_GET
def get_commit_details_async_start(request):
    """å¿«é€Ÿå¯åŠ¨å¼‚æ­¥è·å–æäº¤è¯¦æƒ…çš„ä»»åŠ¡"""
    try:
        sha = request.GET.get('sha', '').strip()
        if not sha:
            return JsonResponse(error_response("Missing required parameter: " + 'sha'), status=400)
        
        # è·å–ä»“åº“ä¿¡æ¯
        repo_owner = request.GET.get('repo_owner', '').strip()
        repo_name = request.GET.get('repo_name', '').strip()
        
        include_diff = request.GET.get('include_diff', 'true').lower() == 'true'
        task = fetch_github_data_async.delay(
            'commit_details', 
            repo_owner=repo_owner, 
            repo_name=repo_name, 
            sha=sha, 
            include_diff=include_diff
        )
        
        logger.info(f"å¯åŠ¨å¼‚æ­¥è·å–æäº¤è¯¦æƒ…ä»»åŠ¡: {task.id}, sha={sha[:8]}")
        
        return JsonResponse(success_response({
            'task_id': task.id,
            'status': 'pending',
            'message': f'å¼‚æ­¥ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ­£åœ¨è·å–æäº¤ {sha[:8]} çš„è¯¦æƒ…',
            'data_type': 'commit_details',
            'params': {'sha': sha, 'include_diff': include_diff},
            'check_url': f'/ai/task-status/{task.id}/'
        }))
        
    except Exception as e:
        return JsonResponse(error_response(str(e), 500), status=500)


# ==================== Ollamaåˆ†ææ¥å£ ====================

@require_POST
@csrf_exempt
def start_ollama_analysis_api(request):
    """å¯åŠ¨Ollamaåˆ†æä»»åŠ¡ (å·²åºŸå¼ƒ)"""
    return JsonResponse(error_response(
        'This API is deprecated. Ollama analysis is now automatically triggered by webhook events.', 
        400
    ), status=400)


@require_POST
@csrf_exempt
def analyze_single_commit_api(request):
    """åˆ†æå•ä¸ªæäº¤ (å·²åºŸå¼ƒ)"""
    return JsonResponse(error_response(
        'This API is deprecated. Single commit analysis is now automatically triggered by webhook events.', 
        400
    ), status=400)


@require_GET
def get_unanalyzed_commits_api(request):
    """è·å–æœªåˆ†æçš„æäº¤åˆ—è¡¨"""
    try:
        limit = int(request.GET.get('limit', 20))
        if limit < 1 or limit > 100:
            return JsonResponse(error_response('limit must be between 1 and 100', 400), status=400)
        
        # åŠŸèƒ½å·²ç¦ç”¨ - ä¸å†å­˜å‚¨æäº¤åˆ†ææ•°æ®
        return JsonResponse(success_response({
            'unanalyzed_commits': [],
            'count': 0,
            'limit': limit,
            'message': 'æäº¤åˆ†æå­˜å‚¨åŠŸèƒ½å·²ç¦ç”¨'
        }))
        
    except ValueError:
        return JsonResponse(error_response('limit must be an integer', 400), status=400)
    except Exception as e:
        logger.error(f"è·å–æœªåˆ†ææäº¤å¤±è´¥: {e}")
        return JsonResponse(error_response(str(e), 500), status=500)


# ==================== å¥åº·æ£€æŸ¥æ¥å£ ====================

@require_GET
def health_check(request):
    """
    ç³»ç»Ÿå¥åº·æ£€æŸ¥æ¥å£
    ç”¨äº Docker å®¹å™¨å¥åº·æ£€æŸ¥å’Œè´Ÿè½½å‡è¡¡å™¨çŠ¶æ€æ£€æµ‹
    """
    try:
        health_status = {
            'status': 'healthy',
            'timestamp': timezone.now().isoformat(),
            'services': {}
        }
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        try:
            from django.db import connection
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
                health_status['services']['database'] = 'healthy'
        except Exception as e:
            health_status['services']['database'] = f'unhealthy: {str(e)}'
            health_status['status'] = 'degraded'
        
        # æ£€æŸ¥ Redis è¿æ¥ (Celery)
        try:
            from celery import current_app
            inspect = current_app.control.inspect()
            stats = inspect.stats()
            if stats:
                health_status['services']['redis'] = 'healthy'
                health_status['services']['celery_workers'] = len(stats)
            else:
                health_status['services']['redis'] = 'healthy'
                health_status['services']['celery_workers'] = 0
        except Exception as e:
            health_status['services']['redis'] = f'unhealthy: {str(e)}'
            health_status['services']['celery_workers'] = 0
            health_status['status'] = 'degraded'
        
        # æ£€æŸ¥ Ollama æœåŠ¡
        try:
            from .ollama_client import OllamaClient
            ollama_client = OllamaClient()
            # ç®€å•çš„å¥åº·æ£€æŸ¥ï¼Œä¸è¿›è¡Œå®é™…çš„æ¨¡å‹è°ƒç”¨
            models = ollama_client.list_models()
            if models.get('status') == 'success':
                health_status['services']['ollama'] = 'healthy'
                health_status['services']['ollama_models'] = len(models.get('models', []))
            else:
                health_status['services']['ollama'] = 'unhealthy'
                health_status['status'] = 'degraded'
        except Exception as e:
            health_status['services']['ollama'] = f'unhealthy: {str(e)}'
            health_status['status'] = 'degraded'
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        try:
            import shutil
            disk_usage = shutil.disk_usage('/')
            free_space_gb = disk_usage.free / (1024**3)
            health_status['services']['disk_space'] = f'{free_space_gb:.2f}GB free'
            if free_space_gb < 1:  # å°‘äº1GBæ—¶æ ‡è®°ä¸ºä¸å¥åº·
                health_status['status'] = 'degraded'
        except Exception as e:
            health_status['services']['disk_space'] = f'unknown: {str(e)}'
        
        # æ ¹æ®æ•´ä½“çŠ¶æ€è®¾ç½® HTTP çŠ¶æ€ç 
        if health_status['status'] == 'healthy':
            return JsonResponse(success_response(health_status))
        else:
            return JsonResponse(success_response(health_status), status=503)  # Service Unavailable
            
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return JsonResponse(error_response(f'Health check failed: {str(e)}', 500), status=500)


@require_GET
def health_simple(request):
    """
    ç®€å•çš„å¥åº·æ£€æŸ¥æ¥å£ - ä»…æ£€æŸ¥åº”ç”¨æ˜¯å¦è¿è¡Œ
    ç”¨äºå¿«é€Ÿçš„å­˜æ´»æ€§æ£€æŸ¥
    """
    return JsonResponse(success_response({
        'status': 'ok',
        'timestamp': timezone.now().isoformat(),
        'message': 'Application is running'
    }))


# ==================== æ¨é€æ¥å£ ====================

@require_POST
@csrf_exempt
def start_push_task_api(request):
    """å¯åŠ¨æ¨é€ä»»åŠ¡"""
    try:
        data = json.loads(request.body)
        delay_seconds = data.get('delay_seconds', 3)  # é»˜è®¤3ç§’å»¶è¿Ÿ
        
        # éªŒè¯å»¶è¿Ÿæ—¶é—´
        if not isinstance(delay_seconds, (int, float)) or delay_seconds < 0:
            return JsonResponse(error_response('delay_seconds must be a non-negative number', 400), status=400)
        
        # å¯åŠ¨æ¨é€ä»»åŠ¡
        task = start_push_task(delay_seconds)
        
        logger.info(f"å¯åŠ¨æ¨é€ä»»åŠ¡: {task.id}")
        
        return JsonResponse(success_response({
            'task_id': task.id,
            'message': 'æ¨é€ä»»åŠ¡å·²å¯åŠ¨',
            'delay_seconds': delay_seconds,
            'check_url': f'/ai/task-status/{task.id}/'
        }))
        
    except json.JSONDecodeError:
        return JsonResponse(error_response('Invalid JSON payload', 400), status=400)
    except Exception as e:
        logger.error(f"å¯åŠ¨æ¨é€ä»»åŠ¡å¤±è´¥: {e}")
        return JsonResponse(error_response(str(e), 500), status=500)


@require_GET
def get_unpushed_commits_api(request):
    """è·å–æœªæ¨é€çš„åˆ†æç»“æœåˆ—è¡¨"""
    try:
        limit = int(request.GET.get('limit', 20))
        if limit < 1 or limit > 100:
            return JsonResponse(error_response('limit must be between 1 and 100', 400), status=400)
        
        # æ•°æ®åº“å­˜å‚¨åŠŸèƒ½å·²ç¦ç”¨
        unpushed_records = []
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        commits_data = []
        for record in unpushed_records:
            commits_data.append({
                'commit_sha': record.commit_sha,
                'short_sha': record.commit_sha[:8],
                'author_name': record.author_name,
                'commit_message': record.commit_message[:100] + '...' if len(record.commit_message) > 100 else record.commit_message,
                'commit_timestamp': record.commit_timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                'analysis_length': len(record.analysis_suggestion),
                'code_diff_length': len(record.code_diff) if record.code_diff else 0,
                'created_at': record.created_at.strftime('%Y-%m-%d %H:%M:%S')
            })
        
        return JsonResponse(success_response({
            'unpushed_commits': commits_data,
            'count': len(commits_data),
            'limit': limit,
            'message': f'æ‰¾åˆ° {len(commits_data)} ä¸ªæœªæ¨é€çš„åˆ†æç»“æœ'
        }))
        
    except ValueError:
        return JsonResponse(error_response('limit must be an integer', 400), status=400)
    except Exception as e:
        logger.error(f"è·å–æœªæ¨é€æäº¤å¤±è´¥: {e}")
        return JsonResponse(error_response(str(e), 500), status=500)